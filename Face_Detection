{
  "metadata": {
    "name": "New JSNB",
    "language_info": {
      "name": "JavaScipt",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Face Recognition</title>\n  <!-- Include Cropper.js library -->\n  <link rel=\"stylesheet\" href=\"https://unpkg.com/cropperjs/dist/cropper.css\">\n  <style>\n   #container {\n      display: flex;\n      justify-content: space-between;\n      width: 800px; /* Adjust the total width as needed */\n      margin: auto; /* Center the container */\n    }\n\n    #videoContainer {\n      position: relative;\n      width: 240px; /* Adjust to your video stream width */\n      height: 240px; /* Adjust to your video stream height */\n    }\n\n    #video, #canvas {\n      position: absolute;\n      top: 0;\n      left: 0;\n    }\n  </style>\n</head>\n<body>\n  <div id=\"container\">\n    <div id=\"videoContainer\">\n      \t\t\t<video id=\"video\" width=\"240\" height=\"180\" autoplay></video>\n         \n            <canvas id=\"canvas\" width=\"240\" height=\"240\"></canvas>\n     </div>\n  \n  </div>\n  <div>\n \t\t <button id=\"captureBtn\">Capture</button>\n\t\t <button id=\"processBtn\">Process</button>\n  </div>\n\n</body>\n</html>\n\n",
      "status": "",
      "output": "\n\n\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Face Recognition</title>\n  <!-- Include Cropper.js library -->\n  <link rel=\"stylesheet\" href=\"https://unpkg.com/cropperjs/dist/cropper.css\">\n  <style>\n   #container {\n      display: flex;\n      justify-content: space-between;\n      width: 800px; /* Adjust the total width as needed */\n      margin: auto; /* Center the container */\n    }\n\n    #videoContainer {\n      position: relative;\n      width: 240px; /* Adjust to your video stream width */\n      height: 240px; /* Adjust to your video stream height */\n    }\n\n    #video, #canvas {\n      position: absolute;\n      top: 0;\n      left: 0;\n    }\n  </style>\n\n\n  <div id=\"container\">\n    <div id=\"videoContainer\">\n      \t\t\t<video id=\"video\" width=\"240\" height=\"180\" autoplay=\"\"></video>\n         \n            <canvas id=\"canvas\" width=\"240\" height=\"180\"></canvas>\n     </div>\n  \n  </div>\n  <div>\n \t\t <button id=\"captureBtn\">Capture</button>\n\t\t <button id=\"processBtn\">Process</button>\n  </div>\n\n\n\n\n",
      "type": "html"
    },
    {
      "code": "  import('https://unpkg.com/face-api.js@latest/dist/face-api.js')",
      "status": "[1]<br><span style=\"font-size:8px\">89ms<span></span></span>",
      "output": "{} <br>",
      "type": "code"
    },
    {
      "code": "\nPromise.all([\n faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/tiny_face_detector_model-weights_manifest.json'),\n  faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_landmark_68_model-weights_manifest.json'),\n  faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_recognition_model-weights_manifest.json'),\n faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_expression_model-weights_manifest.json')\n]).then(() => {\n  // Your code to handle the loaded models\n  console.log(\"Models loaded successfully\");\n  \n});",
      "status": "[2]<br><span style=\"font-size:8px\">606ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "var video = document.getElementById('video');     \nvar capture =  document.getElementById('captureBtn');   \nvar process =  document.getElementById('processBtn');   \n\n\ncapture.addEventListener(\"click\",()=>{\n// Access the camera andget video stream..\n      navigator.mediaDevices.getUserMedia({ video: true })\n        .then((cameraStream) => {\n          stream = cameraStream;\n          video.srcObject = cameraStream;\n        })\n        .catch((error) => {\n         show('Error accessing camera:', error);\n        });\n}\n)",
      "status": "[3]<br><span style=\"font-size:8px\">0ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "process.addEventListener('click', () => {\nconst canvas = document.getElementById('canvas');\n\n  const displaySize = { width: video.width, height: video.height }\n  \n  canvas.width = displaySize.width;\ncanvas.height = displaySize.height;\n  \n  faceapi.matchDimensions(canvas, displaySize)\n  setInterval(async () => {\n    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions()\n    const resizedDetections = faceapi.resizeResults(detections, displaySize)\n    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)\n    faceapi.draw.drawDetections(canvas, resizedDetections)\n    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)\n    faceapi.draw.drawFaceExpressions(canvas, resizedDetections)\n  }, 100)\n})",
      "status": "[4]<br><span style=\"font-size:8px\">0ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "",
      "status": "[5]<br><span style=\"font-size:8px\">0ms<span></span></span>",
      "output": "",
      "type": "code"
    }
  ],
  "source": "https://github.com/gopi-suvanam/jsnb",
  "run_on_load": false
}